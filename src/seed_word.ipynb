{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\damia\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_SEED_WORDS = 50\n",
    "REMOVED = {'i','thou','thee', 'o', '\\'t', 'ah', 'ye', 'someone', 'till', 'oh', 'come', '~' ,'thy', 'thing', 'something', 'shit', 'everyone', 'everything', 'person', 'ass', 'anyone', 'lol', 'im', 'fuck', 'anything', 'gon', 'bitch', 'twitter', 'lot', 'cause'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "haiku_path = '../input/haikus.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame of the haiku dataset\n",
    "# cols: [0, 1, 2, source, 0_syllables, 1_syllables, 2_syllables]\n",
    "df = pd.read_csv(haiku_path)\n",
    "df = df[df['source'].isin(('tempslibres', 'haikuzao', 'sballas'))]\n",
    "df = df.drop(columns='source')\n",
    "df = df.drop(columns=['%s_syllables' % i for i in range(3)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14078/14078 [01:54<00:00, 123.35it/s]\n"
     ]
    }
   ],
   "source": [
    "nouns = Counter()\n",
    "noun_phrases = Counter()\n",
    "\n",
    "for i in tqdm(range(len(df))):\n",
    "  for j in range(3):\n",
    "    line = str(df[str(j)].iloc[i])\n",
    "    tokens = nltk.word_tokenize(line)\n",
    "    \n",
    "    prev_pos = None\n",
    "    prev_tok = None\n",
    "    for tok, pos in nltk.pos_tag(tokens):\n",
    "      tok = tok.lower()\n",
    "      if pos == 'NN':\n",
    "        if prev_pos == 'JJ':\n",
    "          noun_phrases[f'{prev_tok} {tok}'] += 1\n",
    "        nouns[tok] += 1\n",
    "      prev_pos = pos\n",
    "      prev_tok = tok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_most_frequent(dictionary):\n",
    "  return list(sorted(dictionary.items(), key=lambda item: item[1], reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_words(corpus, to_remove):\n",
    "  return [w for w in corpus if w not in to_remove]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('full moon', 101),\n",
       " ('new year', 69),\n",
       " ('indian summer', 47),\n",
       " ('new moon', 30),\n",
       " ('distant thunder', 26),\n",
       " ('last night', 24),\n",
       " ('blue sky', 22),\n",
       " ('old man', 21),\n",
       " ('cold rain', 21),\n",
       " ('cold night', 21),\n",
       " ('deep winter', 20),\n",
       " ('low tide', 18),\n",
       " ('warm day', 18),\n",
       " ('last day', 17),\n",
       " ('last year', 17),\n",
       " ('early spring', 15),\n",
       " ('soft rain', 15),\n",
       " ('milky way', 15),\n",
       " ('late summer', 14),\n",
       " ('open window', 14),\n",
       " ('fresh snow', 14),\n",
       " ('high tide', 14),\n",
       " ('last light', 13),\n",
       " ('cold morning', 13),\n",
       " ('small town', 13),\n",
       " ('old dog', 13),\n",
       " ('deep autumn', 12),\n",
       " ('last time', 12),\n",
       " ('rainy day', 11),\n",
       " ('little girl', 11),\n",
       " ('blue heron', 11),\n",
       " ('cold moon', 11),\n",
       " ('memorial day', 11),\n",
       " ('late afternoon', 10),\n",
       " ('gibbous moon', 10),\n",
       " ('long night', 10),\n",
       " ('other side', 10),\n",
       " ('old cat', 10),\n",
       " ('old friend', 9),\n",
       " ('cool morning', 9),\n",
       " ('old pond', 9),\n",
       " ('first time', 9),\n",
       " ('stray dog', 9),\n",
       " ('white butterfly', 9),\n",
       " ('steady rain', 9),\n",
       " ('heavy rain', 9),\n",
       " ('hot afternoon', 8),\n",
       " ('small talk', 8),\n",
       " ('new coolness', 8),\n",
       " ('warm rain', 8)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_most_frequent(noun_phrases)[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['moon', 'rain', 'morning', 'night', 'summer', 'winter', 'day', 'spring', 'autumn', 'wind', 'sky', 'snow', 'sun', 'light', 'window', 'end', 'scent', 'shadow', 'dog', 'sound', 'heat', 'fog', 'home', 'year', 'river', 'garden', 'afternoon', 'dusk', 'tree', 'sunset', 'breeze', 'song', 'cat', 'smell', 'dawn', 'water', 'storm', 'time', 'way', 'evening', 'grass', 'silence', 'tea', 'mother', 'nan', 'mist', 'leaf', 'house', 'child', 'blue']\n"
     ]
    }
   ],
   "source": [
    "seed_words = get_most_frequent(nouns)\n",
    "seed_words = [e[0] for e in seed_words]\n",
    "seed_words = remove_words(seed_words, REMOVED)\n",
    "seed_words = seed_words[:NUM_SEED_WORDS]\n",
    "print(seed_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"seed_words.txt\", \"w\") as f:\n",
    "  for sw in seed_words:\n",
    "    f.write(str(sw) + \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ac59ebe37160ed0dfa835113d9b8498d9f09ceb179beaac4002f036b9467c963"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
