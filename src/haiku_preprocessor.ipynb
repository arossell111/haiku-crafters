{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import nltk\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "haiku_path = '../input/haikus.csv'\n",
    "seed_word_path = './seed_words.txt'\n",
    "\n",
    "# eventually would be cool to load this from a config/hyperparam json file\n",
    "hyperparams = {\n",
    "    'preprocessing': {\n",
    "        'max_line_len_quantile': 0.9,\n",
    "        'min_line_syllables': 3\n",
    "    },\n",
    "    'model': {\n",
    "        'latent_dim': 2048,\n",
    "        'epochs': 20,\n",
    "        'learning_rate': 0.01\n",
    "    }\n",
    "    \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame of the haiku dataset\n",
    "# cols: [0, 1, 2, 0_syllables, 1_syllables, 2_syllables]\n",
    "df = pd.read_csv(haiku_path)\n",
    "# remove twaiku and gutenberg data because it's weird sometimes.\n",
    "# df = df[df.source == 'twaiku' or df.source == 'gutenberg']\n",
    "df = df.drop(columns='source')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duplicate lines with ambiguous syllable counts\n",
    "# i.e. syllable counts with a comma because there exists multiple pronunciations\n",
    "for i in range(3):\n",
    "  col = '%s_syllables' % i\n",
    "  df[col] = df[col].str.split(',', expand=False)\n",
    "  df = df.explode(col)\n",
    "  df[col] = df[col].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop samples that have lines longer than 90th percentile\n",
    "# may want to modify this value and see how it changes\n",
    "quantile = hyperparams['preprocessing']['max_line_len_quantile']\n",
    "max_len = int(max([df[str(i)].str.len().quantile(quantile) for i in range(3)]))\n",
    "df = df[\n",
    "  (df['0'].str.len() < max_len) & \n",
    "  (df['1'].str.len() < max_len) & \n",
    "  (df['2'].str.len() < max_len)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop samples that have lines longer than 90th percentile\n",
    "# may want to modify this value and see how it changes\n",
    "min_syll = hyperparams['preprocessing']['min_line_syllables']\n",
    "df = df[\n",
    "  (df['0_syllables'] >= min_syll) & \n",
    "  (df['1_syllables'] >= min_syll) & \n",
    "  (df['2_syllables'] >= min_syll)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_words = set()\n",
    "with open(seed_word_path, 'r') as f:\n",
    "  for line in f:\n",
    "    seed_words.add(str(line.strip()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 143715/143715 [20:05<00:00, 119.21it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(df))):\n",
    "  seeds = []\n",
    "  for j in range(3):\n",
    "    line = str(df[str(j)].iloc[i])\n",
    "    tokens = nltk.word_tokenize(line)\n",
    "    for tok, pos in nltk.pos_tag(tokens):\n",
    "      if pos != 'NN':\n",
    "        continue\n",
    "      tok = tok.lower()\n",
    "      if tok in seed_words:\n",
    "        seeds.append(tok)\n",
    "  labels.append(','.join(seeds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          0                                1  \\\n",
      "1             spring rain -             as the doctor speaks   \n",
      "1             spring rain -             as the doctor speaks   \n",
      "3           sunny afternoon               an old man lingers   \n",
      "5             quitting time                the smell of rain   \n",
      "5             quitting time                the smell of rain   \n",
      "...                     ...                              ...   \n",
      "143120     Someone is upset     their team isn't winning the   \n",
      "143122  The write in Mickey   Mouse probably could have been   \n",
      "143122  The write in Mickey   Mouse probably could have been   \n",
      "143124  People really don't       be having shit else better   \n",
      "143127   Today is the first       day of the rest of my LIFE   \n",
      "\n",
      "                            2  0_syllables  1_syllables  2_syllables  \\\n",
      "1           i think of lilacs            3            5            5   \n",
      "1           i think of lilacs            3            5            5   \n",
      "3            near the mailbox            5            5            4   \n",
      "5                in the lobby            3            4            4   \n",
      "5                in the lobby            3            4            4   \n",
      "...                       ...          ...          ...          ...   \n",
      "143120   Super Bowl this year            5            7            5   \n",
      "143122    president this time            5            6            5   \n",
      "143122    president this time            5            7            5   \n",
      "143124  to do with their time            5            7            5   \n",
      "143127     and YES it MATTERS            5            7            5   \n",
      "\n",
      "            label  \n",
      "1          spring  \n",
      "1            rain  \n",
      "3       afternoon  \n",
      "5            time  \n",
      "5           smell  \n",
      "...           ...  \n",
      "143120       year  \n",
      "143122       time  \n",
      "143122       time  \n",
      "143124       time  \n",
      "143127        day  \n",
      "\n",
      "[36014 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "# add label column from labels list\n",
    "df['label'] = labels\n",
    "# remove unlabeled rows\n",
    "df['label'].replace('', np.nan, inplace=True)\n",
    "df.dropna(subset=['label'], inplace=True)\n",
    "# expand rows with multiple labels\n",
    "df['label'] = df['label'].str.split(',', expand=False)\n",
    "df = df.explode('label')\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../input/labeled_haikus.csv')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ac59ebe37160ed0dfa835113d9b8498d9f09ceb179beaac4002f036b9467c963"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
